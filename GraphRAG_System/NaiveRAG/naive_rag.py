import json
import numpy as np
import faiss
from typing import List, Tuple
from neo4j import GraphDatabase
import dashscope
from sklearn.metrics import precision_score, recall_score, f1_score

# é…ç½®è·¯å¾„ä¸å‚æ•°
EMBED_PATH = "/home/lym/GraphRAG4OralHealth/GraphRAG_System/data/node_summarization_embeddings.npz"
TEST_FILES = [
    "/home/lym/GraphRAG4OralHealth/Benchmark/GraphRAG/1hop.json"
]
NEO4J_URL = "bolt://127.0.0.1:9687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "medical_neo4j"
TOP_K = 3
EMBED_DIM = 1024

dashscope.api_key = "sk-969f4200d53442a2a1733d1c0b1fb330"

# 1. è½½å…¥æœ¬åœ°åµŒå…¥
def load_embeddings(path: str):
    data = np.load(path)
    return data["keys"], data["embeddings"]

# 2. æ„å»º FAISS ç´¢å¼•
def build_index(embeddings: np.ndarray):
    index = faiss.IndexFlatL2(EMBED_DIM)
    index.add(embeddings)
    return index

def get_embedding(texts: List[str], batch_size: int = 8) -> List[List[float]]:
    all_embeddings = []
    max_len = 3000  # é™åˆ¶æœ€å¤§é•¿åº¦ï¼Œé¿å…å¤§æ¨¡å‹å¼‚å¸¸

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch = [t[:max_len] for t in batch]  # æ¸…æ´—å­—ç¬¦ä¸²
        try:
            response = dashscope.TextEmbedding.call(
                model="text-embedding-v3",
                input=batch
            )
            if not response or "output" not in response or "embeddings" not in response["output"]:
                raise ValueError(f"åµŒå…¥æ¥å£è¿”å›å¼‚å¸¸ï¼š{response}")
            all_embeddings.extend([item["embedding"] for item in response["output"]["embeddings"]])
        except Exception as e:
            print(f"åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼ˆbatch {i}-{i+len(batch)}ï¼‰: {e}")
            all_embeddings.extend([[0.0] * 1024 for _ in batch])

    return all_embeddings


# 4. ä» Neo4j è·å–åç§°
def fetch_names_from_neo4j(ids: List[int]) -> List[str]:
    driver = GraphDatabase.driver(NEO4J_URL, auth=(NEO4J_USER, NEO4J_PASSWORD))
    names = []
    with driver.session() as session:
        for node_id in ids:
            result = session.run("MATCH (n) WHERE n.åç§° = $id RETURN n.åç§° AS name", id=node_id)
            record = result.single()
            if record and record["name"]:
                names.append(str(record["name"]))
    driver.close()
    return names
# 5.åå¤„ç†æ­¥éª¤
def filter_with_llm(question: str, nodes: List[str], model="qwen-plus", api_key="sk-969f4200d53442a2a1733d1c0b1fb330") -> List[str]:
    from dashscope import Generation
    filtered = []
    
    for i, node_content in enumerate(nodes):
        prompt = f"""
    ä½ æ˜¯ä¸€åå£è…”åŒ»å­¦çŸ¥è¯†å›¾è°±ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åˆ¤æ–­é—®é¢˜æ˜¯å¦ä¸èŠ‚ç‚¹å†…å®¹ç›¸å…³,ç›¸å…³æ ‡å‡†ä¸ºé—®é¢˜å‡ºç°èŠ‚ç‚¹åç§°æˆ–æ¶‰åŠèŠ‚ç‚¹ç›¸å…³å±æ€§ï¼Œå¦åˆ™ä¸€å¾‹ä¸ç›¸å…³ã€‚
    ã€é—®é¢˜ã€‘
    {question}
    ã€èŠ‚ç‚¹å†…å®¹ã€‘
    {node_content}
    è¯·å›ç­”ï¼šâ€œç›¸å…³â€æˆ–â€œä¸ç›¸å…³â€,ä¸è¦è¾“å‡ºæ— å…³å†…å®¹ã€‚
    """

        try:
            response = Generation.call(
                model=model,
                api_key=api_key,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                result_format="message"
            )
            reply = response["output"]["choices"][0]["message"]["content"].strip()
            if "ä¸ç›¸å…³" in reply:
                continue
            else:
                filtered.append(node_content)
        except Exception as e:
            print(f"[!] LLM ç­›é€‰å¤±è´¥ï¼ˆèŠ‚ç‚¹{i}ï¼‰ï¼š{e}")
            continue

    return filtered
def fetch_contents_from_neo4j(ids: List[int]) -> List[str]:
    """
    æ ¹æ®èŠ‚ç‚¹ ID åˆ—è¡¨ï¼Œä» Neo4j è·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§ï¼Œå¹¶æ‹¼æ¥æˆæ–‡æœ¬æ ¼å¼ã€‚
    """
    driver = GraphDatabase.driver(NEO4J_URL, auth=(NEO4J_USER, NEO4J_PASSWORD))
    contents = []

    with driver.session() as session:
        for node_id in ids:
            result = session.run(
                "MATCH (n) WHERE n.åç§° = $id RETURN properties(n) AS props", id=node_id
            )
            record = result.single()
            if record and record["props"]:
                props = record["props"]
                # æ‹¼æ¥ä¸ºæ–‡æœ¬ï¼škey1: val1 key2: val2 ...
                content = "\n".join([f"{k}: {v}" for k, v in props.items()])
                contents.append(content)

    driver.close()
    return contents
import re

def extract_names_from_contents(contents: List[str]) -> List[str]:
    """
    ä»æ‹¼æ¥æ–‡æœ¬ä¸­æå–â€œåç§°â€å­—æ®µçš„å€¼ã€‚
    """
    names = []
    for content in contents:
        match = re.search(r"åç§°[:ï¼š]\s*(.+)", content)
        if match:
            name = match.group(1).strip()
            # å»é™¤æ¢è¡Œç¬¦æˆ–åç»­å­—æ®µå¹²æ‰°ï¼ˆæ¯”å¦‚ åç§°: XXX\nå…¶ä»–å±æ€§: ...ï¼‰
            name = name.split("\n")[0].strip()
            names.append(name)
        else:
            names.append("")  # æˆ–è€… names.append("æœªçŸ¥åç§°")
    return names


# 6. æ‰§è¡Œè¯„ä¼°
import time

def evaluate_naive_rag():
    node_ids, embeddings = load_embeddings(EMBED_PATH)
    print("âœ… åŠ è½½å‘é‡ shape:", embeddings.shape)
    index = build_index(embeddings)

    all_prec, all_rec, all_f1 = [], [], []
    all_times = []

    for file_path in TEST_FILES:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        for idx, sample in enumerate(data):
            query = sample["é—®é¢˜"]
            gt_nodes = []

            start_time = time.time()  # â±ï¸ è®¡æ—¶å¼€å§‹

            # è·å– groundtruth åç§°
            gt = sample["æ£€ç´¢æ–‡æœ¬"]
            if isinstance(gt, dict) and "nodes" in gt:
                gt_nodes = [n["properties"]["åç§°"] for n in gt["nodes"]]
            elif isinstance(gt, dict) and "properties" in gt:
                gt_nodes = [gt["properties"]["åç§°"]]
            else:
                print(f"[!] è·³è¿‡æ— æ•ˆæ ·æœ¬ idx={idx}")
                continue

            # æŸ¥è¯¢å‘é‡ â†’ FAISS æ£€ç´¢
            query_vec = get_embedding([query])[0]
            D, I = index.search(np.array([query_vec]), TOP_K)
            pred_ids = [node_ids[i] for i in I[0]]
            node_contents = fetch_contents_from_neo4j(pred_ids)
            filtered_contents = filter_with_llm(query, node_contents)
            pred_names = extract_names_from_contents(filtered_contents)

            # è®¡ç®—æŒ‡æ ‡
            pred_set = set(pred_names)
            gt_set = set(gt_nodes)
            tp = len(pred_set & gt_set)
            precision = tp / len(pred_set) if pred_set else 0
            recall = tp / len(gt_set) if gt_set else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0

            all_prec.append(precision)
            all_rec.append(recall)
            all_f1.append(f1)

            elapsed = time.time() - start_time  # â±ï¸ è®¡æ—¶ç»“æŸ
            all_times.append(elapsed)

            # æ‰“å°æ¯æ¡ç»“æœ
            print(f"ğŸ” é—®é¢˜{idx+1}ï¼š{query}")
            print(f"GT: {gt_nodes}")
            print(f"Retrieved: {pred_names}")
            print(f"Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}, Time: {elapsed:.2f}s")
            print("-" * 50)

    # æ±‡æ€»æ‰“å°
    print("\nğŸ¯ æ€»ä½“è¯„ä¼°ç»“æœï¼š")
    print(f"Avg Precision: {np.mean(all_prec):.3f}")
    print(f"Avg Recall: {np.mean(all_rec):.3f}")
    print(f"Avg F1: {np.mean(all_f1):.3f}")
    print(f"â±ï¸ Avg Time per question: {np.mean(all_times):.2f} seconds")


# æ‰§è¡Œä¸»æµç¨‹
if __name__ == "__main__":
    evaluate_naive_rag()
