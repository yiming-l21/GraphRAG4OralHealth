{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 解析完成，已保存到：result.json\n",
      "✅ 所有 Q/A 对已保存到：qa.json 692\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "功能：解析包含多个结构块的文本文件，每块包含 SET、CONTENT、QUESTIONS、GRAPH 区域。\n",
    "将其转换为 JSON 格式结构，保存到 result.json。\n",
    "\n",
    "文本结构示例：\n",
    "SET48\n",
    "CONTENT\n",
    "...\n",
    "QUESTIONS\n",
    "Q\n",
    "...\n",
    "A\n",
    "...\n",
    "GRAPH\n",
    "{ ... }\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "def parse_multiple_blocks(lines):\n",
    "    \"\"\"\n",
    "    解析文本中的多个结构块，返回一个 JSON 对象列表。\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    current_block = None\n",
    "\n",
    "    # 状态控制\n",
    "    in_content = False\n",
    "    in_questions = False\n",
    "    in_graph = False\n",
    "\n",
    "    # 缓存区\n",
    "    content_buffer = []\n",
    "    question_buffer = None\n",
    "    answer_buffer = None\n",
    "    graph_buffer = []\n",
    "\n",
    "    def flush_current_block():\n",
    "        \"\"\"\n",
    "        将当前结构块缓存内容写入 blocks 列表，并清空状态。\n",
    "        \"\"\"\n",
    "        nonlocal current_block, content_buffer, graph_buffer\n",
    "        nonlocal in_content, in_questions, in_graph\n",
    "\n",
    "        if current_block is None:\n",
    "            return\n",
    "\n",
    "        # 内容整理\n",
    "        current_block[\"CONTENT\"] = \"\\n\".join(content_buffer) if content_buffer else \"\"\n",
    "\n",
    "        if graph_buffer:\n",
    "            graph_str = \"\\n\".join(graph_buffer)\n",
    "            if not graph_str.strip().startswith(\"{\"):\n",
    "                graph_str = \"{\" + graph_str + \"}\"\n",
    "            try:\n",
    "                graph_json = json.loads(graph_str)\n",
    "                current_block[\"GRAPH\"] = graph_json\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"GRAPH 区块 JSON 解析失败：{e}\\n内容如下：\\n{graph_str}\")\n",
    "        else:\n",
    "            current_block[\"GRAPH\"] = {}\n",
    "\n",
    "        blocks.append(current_block)\n",
    "\n",
    "        # 重置状态\n",
    "        current_block = None\n",
    "        content_buffer.clear()\n",
    "        graph_buffer.clear()\n",
    "        in_content = False\n",
    "        in_questions = False\n",
    "        in_graph = False\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        # 1. 新块开始\n",
    "        if line.startswith(\"SET\"):\n",
    "            if current_block is not None:\n",
    "                flush_current_block()\n",
    "            current_block = {\n",
    "                \"SET\": line,\n",
    "                \"CONTENT\": \"\",\n",
    "                \"QUESTIONS\": [],\n",
    "                \"GRAPH\": {}\n",
    "            }\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # 如果 SET 块未开始，忽略其他行\n",
    "        if current_block is None:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # 区块切换逻辑\n",
    "        if line == \"CONTENT\":\n",
    "            in_content, in_questions, in_graph = True, False, False\n",
    "            i += 1\n",
    "            continue\n",
    "        elif line .startswith( \"QUESTION\"):\n",
    "            in_content, in_questions, in_graph = False, True, False\n",
    "            i += 1\n",
    "            continue\n",
    "        elif line == \"GRAPH\":\n",
    "            in_content, in_questions, in_graph = False, False, True\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # CONTENT 区块采集\n",
    "        if in_content:\n",
    "            content_buffer.append(line)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "                # QUESTIONS 区块采集\n",
    "        if in_questions:\n",
    "            if line == \"Q\":\n",
    "                question_lines = []\n",
    "                i += 1\n",
    "                # 收集多行 Q 内容，直到遇到 A / Q / GRAPH / CONTENT\n",
    "                while i < len(lines):\n",
    "                    next_line = lines[i].strip()\n",
    "                    if next_line in {\"Q\", \"A\", \"GRAPH\", \"CONTENT\"}:\n",
    "                        break\n",
    "                    question_lines.append(next_line)\n",
    "                    i += 1\n",
    "                question_buffer = \"\\n\".join(question_lines)\n",
    "                continue\n",
    "\n",
    "            elif line == \"A\":\n",
    "                answer_lines = []\n",
    "                i += 1\n",
    "                # 收集多行 A 内容，直到遇到 Q / A / GRAPH / CONTENT\n",
    "                while i < len(lines):\n",
    "                    next_line = lines[i].strip()\n",
    "                    if next_line in {\"Q\", \"A\", \"GRAPH\", \"CONTENT\"}:\n",
    "                        break\n",
    "                    answer_lines.append(next_line)\n",
    "                    i += 1\n",
    "                answer_buffer = \"\\n\".join(answer_lines)\n",
    "\n",
    "                # 存储问答对\n",
    "                if question_buffer and answer_buffer:\n",
    "                    current_block[\"QUESTIONS\"].append({\n",
    "                        \"Q\": question_buffer,\n",
    "                        \"A\": answer_buffer\n",
    "                    })\n",
    "                    question_buffer = None\n",
    "                    answer_buffer = None\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                # 非 Q/A 标识行，跳过\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        # GRAPH 区块采集\n",
    "        if in_graph:\n",
    "            graph_buffer.append(line)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # 其他默认跳过\n",
    "        i += 1\n",
    "\n",
    "    # 最后一块补交\n",
    "    if current_block is not None:\n",
    "        flush_current_block()\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_path = \"./raw_text.txt\"\n",
    "    output_path = \"result.json\"\n",
    "\n",
    "    # 读取并预处理\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # 解析文本结构\n",
    "    parsed_blocks = parse_multiple_blocks(raw_lines)\n",
    "\n",
    "    # 写出结果 JSON 文件\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(parsed_blocks, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"✅ 解析完成，已保存到：{output_path}\")\n",
    "    # 提取所有 Q/A 对并写入 qa.json\n",
    "    all_qa_pairs = []\n",
    "    for block in parsed_blocks:\n",
    "        for qa in block.get(\"QUESTIONS\", []):\n",
    "            if \"Q\" in qa and \"A\" in qa:\n",
    "                all_qa_pairs.append({\n",
    "                    \"Q\": qa[\"Q\"],\n",
    "                    \"A\": qa[\"A\"]\n",
    "                })\n",
    "    qa_output_path = \"qa.json\"\n",
    "    with open(qa_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_qa_pairs, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"✅ 所有 Q/A 对已保存到：{qa_output_path}\",len(all_qa_pairs))\n",
    "    with open(\"qa1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_qa_pairs[:350], f, ensure_ascii=False, indent=4)\n",
    "    with open(\"qa2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_qa_pairs[350:], f, ensure_ascii=False, indent=4)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已解析 81 个病例，结果保存在 parsed_cases.json。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# --------------------------------------------\n",
    "# Script: parse_disease_history.py\n",
    "# Purpose: 解析 disease_history.txt 文件中每个病例元素，提取题干、题目、答案和评分要点，输出为 JSON 格式。\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "def parse_element(text):\n",
    "    \"\"\"\n",
    "    解析单个病例元素文本，提取字段：\n",
    "      - id: 病例标识，如 SET51\n",
    "      - 病史: BACKGROUND 部分\n",
    "      - 问题: QUESTION 部分，列表\n",
    "      - 答案: ANSWER 部分，列表\n",
    "      - 评分细则: STANDARD 部分，列表\n",
    "    \"\"\"\n",
    "    id_match = re.search(r\"^(SET\\d+)\", text, re.MULTILINE)\n",
    "    case_id = id_match.group(1) if id_match else None\n",
    "\n",
    "    # 病史题干\n",
    "    stem_match = re.search(r\"BACKGROUND\\s*(.*?)\\s*QUESTION\", text, re.S)\n",
    "    stem = stem_match.group(1).strip() if stem_match else \"\"\n",
    "\n",
    "    # 问题\n",
    "    ques_block_match = re.search(r\"QUESTION\\s*(.*?)\\s*ANSWER\", text, re.S)\n",
    "    questions = []\n",
    "    if ques_block_match:\n",
    "        parts = re.split(r\"^QUE\", ques_block_match.group(1), flags=re.M)\n",
    "        questions = [part.strip() for part in parts if part.strip()]\n",
    "\n",
    "    # 答案\n",
    "    ans_block_match = re.search(r\"ANSWER\\s*(.*?)\\s*STANDARD\", text, re.S)\n",
    "    answers = []\n",
    "    if ans_block_match:\n",
    "        parts = re.split(r\"^ANS\", ans_block_match.group(1), flags=re.M)\n",
    "        answers = [part.strip() for part in parts if part.strip()]\n",
    "\n",
    "    # 提取评分细则\n",
    "    rubric_match = re.search(r\"STANDARD\\s*(.*)\", text, re.S)\n",
    "    rubrics = []\n",
    "    if rubric_match:\n",
    "        raw = rubric_match.group(1)\n",
    "\n",
    "        # 使用 lookahead，保留 STA 开头，避免首段出问题\n",
    "        parts = re.split(r\"(?=^\\s*STA\\s*)\", raw, flags=re.M)\n",
    "\n",
    "        for part in parts:\n",
    "            # 去掉开头的 STA\n",
    "            clean = re.sub(r\"^\\s*STA\\s*\", \"\", part.strip())\n",
    "            if clean:\n",
    "                rubrics.append(clean)\n",
    "\n",
    "    # 校验一致性\n",
    "    max_len = max(len(questions), len(answers), len(rubrics))\n",
    "    while len(answers) < max_len:\n",
    "        answers.append(\"\")\n",
    "    while len(rubrics) < max_len:\n",
    "        rubrics.append(\"\")\n",
    "\n",
    "    return {\n",
    "        \"id\": case_id,\n",
    "        \"病史\": stem,\n",
    "        \"问题\": questions,\n",
    "        \"答案\": answers,\n",
    "        \"评分细则\": rubrics\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_file(file_path):\n",
    "    \"\"\"\n",
    "    读取整个文件，并按 SET 开头拆分多个病例元素，返回解析后的 JSON 列表。\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 按病例分段 (在每个 SET 开头处拆分)\n",
    "    raw_elements = re.split(r\"(?=^SET\\d+)\", content, flags=re.M)\n",
    "    parsed = []\n",
    "    for elem in raw_elements:\n",
    "        elem = elem.strip()\n",
    "        if not elem:\n",
    "            continue\n",
    "        parsed.append(parse_element(elem))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 示例：解析 disease_history.txt 并保存为 JSON\n",
    "    cases = parse_file('disease_history.txt')\n",
    "    with open('parsed_cases.json', 'w', encoding='utf-8') as out:\n",
    "        json.dump(cases, out, ensure_ascii=False, indent=2)\n",
    "    print(f\"已解析 {len(cases)} 个病例，结果保存在 parsed_cases.json。\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 说明：\n",
    "# 1. 使用正则表达式对文本进行分段和提取。\n",
    "# 2. re.S (DOTALL) 使 \".\" 匹配换行，re.M (MULTILINE) 使 ^ 和 $ 匹配每行。\n",
    "# 3. 对题目部分使用 re.split 分割 \"QUE\" 标记，并清洗空白。\n",
    "# 4. 输出 JSON 时保持中文字符。\n",
    "# --------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 总共 53 个 block，692 个问题，目标保留 200 条\n",
      "✅ SET1: 原始 2 → 保留 0\n",
      "✅ SET2: 原始 1 → 保留 1\n",
      "✅ SET3: 原始 3 → 保留 1\n",
      "✅ SET4: 原始 10 → 保留 3\n",
      "✅ SET5: 原始 10 → 保留 3\n",
      "✅ SET6: 原始 10 → 保留 3\n",
      "✅ SET7: 原始 9 → 保留 3\n",
      "✅ SET8: 原始 9 → 保留 3\n",
      "✅ SET9: 原始 10 → 保留 3\n",
      "✅ SET10: 原始 8 → 保留 2\n",
      "✅ SET11: 原始 10 → 保留 3\n",
      "✅ SET12: 原始 10 → 保留 3\n",
      "✅ SET13: 原始 9 → 保留 3\n",
      "✅ SET14: 原始 30 → 保留 9\n",
      "✅ SET15: 原始 32 → 保留 9\n",
      "✅ SET16: 原始 18 → 保留 5\n",
      "✅ SET17: 原始 19 → 保留 5\n",
      "✅ SET18: 原始 7 → 保留 2\n",
      "✅ SET19: 原始 19 → 保留 5\n",
      "✅ SET20: 原始 20 → 保留 6\n",
      "✅ SET21: 原始 20 → 保留 6\n",
      "✅ SET22: 原始 10 → 保留 3\n",
      "✅ SET23: 原始 10 → 保留 3\n",
      "✅ SET24: 原始 10 → 保留 3\n",
      "✅ SET25: 原始 7 → 保留 0\n",
      "✅ SET26: 原始 3 → 保留 0\n",
      "✅ SET27: 原始 2 → 保留 0\n",
      "✅ SET28: 原始 21 → 保留 4\n",
      "✅ SET29: 原始 10 → 保留 3\n",
      "✅ SET30: 原始 21 → 保留 6\n",
      "✅ SET31: 原始 20 → 保留 6\n",
      "✅ SET32: 原始 8 → 保留 2\n",
      "✅ SET33: 原始 10 → 保留 1\n",
      "✅ SET34: 原始 10 → 保留 2\n",
      "✅ SET35: 原始 10 → 保留 3\n",
      "✅ SET36: 原始 9 → 保留 2\n",
      "✅ SET37: 原始 10 → 保留 3\n",
      "✅ SET38: 原始 20 → 保留 1\n",
      "✅ SET39: 原始 21 → 保留 2\n",
      "✅ SET40: 原始 15 → 保留 1\n",
      "✅ SET41: 原始 10 → 保留 3\n",
      "✅ SET42: 原始 20 → 保留 6\n",
      "✅ SET43: 原始 8 → 保留 2\n",
      "✅ SET44: 原始 10 → 保留 3\n",
      "✅ SET45: 原始 16 → 保留 4\n",
      "✅ SET46: 原始 19 → 保留 5\n",
      "✅ SET47: 原始 30 → 保留 7\n",
      "✅ SET48: 原始 21 → 保留 4\n",
      "✅ SET49: 原始 10 → 保留 2\n",
      "✅ SET50: 原始 20 → 保留 4\n",
      "\n",
      "✅ 最终总计保留 163 条，保存到 /home/lym/GraphRAG4OralHealth/Benchmark/Skill Objectives/basic_techniques.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import threading\n",
    "from queue import Queue\n",
    "from typing import List, Dict\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from dashscope import Generation\n",
    "\n",
    "# ✅ Qwen 配置\n",
    "QWEN_API_KEY = \"sk-969f4200d53442a2a1733d1c0b1fb330\"\n",
    "QWEN_CHAT_MODEL = \"qwen-plus\"\n",
    "NUM_THREADS = 8\n",
    "\n",
    "# =====================\n",
    "# 调用 Qwen 评估模型\n",
    "# =====================\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))\n",
    "def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs) -> str:\n",
    "    import dashscope\n",
    "    dashscope.api_key = QWEN_API_KEY\n",
    "\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.extend(history_messages)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = Generation.call(\n",
    "        model=QWEN_CHAT_MODEL,\n",
    "        messages=messages,\n",
    "        result_format='message'\n",
    "    )\n",
    "    return response[\"output\"][\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "def build_evaluation_prompt(q: str, a: str) -> str:\n",
    "    return f\"\"\"\n",
    "你是一名口腔医学考试专家，请对以下问答进行筛选：\n",
    "\n",
    "问题：{q}\n",
    "回答：{a}\n",
    "\n",
    "请判断：\n",
    "1. 是否是口腔医学领域特有的问题？（是/否）\n",
    "2. 是否涉及具体的操作技能？（是/否）\n",
    "3. 答案是否专业、准确、完整，体现较高的知识深度？（是/否）\n",
    "4. 综合判断该问答是否适合作为口腔领域技能评测题目？（是/否）\n",
    "\n",
    "请严格按照如下 JSON 返回：\n",
    "{{\n",
    "  \"领域特异性\": \"是/否\",\n",
    "  \"技能导向\": \"是/否\",\n",
    "  \"答案质量\": \"是/否\",\n",
    "  \"是否推荐\": \"是/否\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def gpt_evaluate(q: str, a: str) -> bool:\n",
    "    prompt = build_evaluation_prompt(q, a)\n",
    "    try:\n",
    "        response = llm_model_func(prompt)\n",
    "        # 提取第一个合法 JSON 对象\n",
    "        match = re.search(r'\\{.*?\\}', response, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"No JSON object found in response.\")\n",
    "        json_str = match.group(0)\n",
    "        result = json.loads(json_str)\n",
    "        return result.get(\"是否推荐\") == \"是\"\n",
    "    except Exception as e:\n",
    "        print(f\"[❌ 模型评估失败] {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Worker 多线程处理 Q&A\n",
    "# =====================\n",
    "def qa_worker(queue: Queue, result_dict: Dict[str, List[Dict]]):\n",
    "    while not queue.empty():\n",
    "        block_id, qa = queue.get()\n",
    "        q, a = qa.get(\"Q\"), qa.get(\"A\")\n",
    "        if not q or not a:\n",
    "            queue.task_done()\n",
    "            continue\n",
    "        if gpt_evaluate(q, a):\n",
    "            result_dict.setdefault(block_id, []).append(qa)\n",
    "        queue.task_done()\n",
    "\n",
    "# =====================\n",
    "# 主函数：读取、按比例筛选、保存\n",
    "# =====================\n",
    "def threaded_blockwise_filter(input_path: str, output_path: str, total_target: int = 200):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        all_blocks = json.load(f)\n",
    "\n",
    "    total_questions = sum(len(b[\"QUESTIONS\"]) for b in all_blocks)\n",
    "    print(f\"📘 总共 {len(all_blocks)} 个 block，{total_questions} 个问题，目标保留 {total_target} 条\")\n",
    "\n",
    "    # 组织任务队列（以问题为单位）\n",
    "    qa_queue = Queue()\n",
    "    block_map = {}  # 用于记录 block_id -> 原始 QA 数量\n",
    "\n",
    "    for block in all_blocks:\n",
    "        block_id = block.get(\"SET\", \"UNKNOWN\")\n",
    "        questions = block.get(\"QUESTIONS\", [])\n",
    "        block_map[block_id] = len(questions)\n",
    "        for qa in questions:\n",
    "            qa_queue.put((block_id, qa))\n",
    "\n",
    "    # 用于保存每个 block 的推荐 QA\n",
    "    result_dict = {}\n",
    "    threads = []\n",
    "\n",
    "    for _ in range(NUM_THREADS):\n",
    "        t = threading.Thread(target=qa_worker, args=(qa_queue, result_dict))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    qa_queue.join()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    # ============================\n",
    "    # 每个 block 取对应比例\n",
    "    # ============================\n",
    "    final_output = []\n",
    "    for block_id, original_count in block_map.items():\n",
    "        keep_count = max(1, round(original_count * total_target / total_questions))\n",
    "        selected = result_dict.get(block_id, [])[:keep_count]\n",
    "        final_output.extend(selected)\n",
    "        print(f\"✅ {block_id}: 原始 {original_count} → 保留 {len(selected)}\")\n",
    "\n",
    "    print(f\"\\n✅ 最终总计保留 {len(final_output)} 条，保存到 {output_path}\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# =====================\n",
    "# 入口函数\n",
    "# =====================\n",
    "if __name__ == '__main__':\n",
    "    threaded_blockwise_filter(\n",
    "        input_path=\"/home/lym/GraphRAG4OralHealth/Benchmark/Skill Objectives/raw_data.json\",\n",
    "        output_path=\"/home/lym/GraphRAG4OralHealth/Benchmark/Skill Objectives/basic_techniques.json\",\n",
    "        total_target=200\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
